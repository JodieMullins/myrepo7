{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11146250-384e-4881-b718-15fcc0c2189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589232e9-f379-4605-8db9-6187a8c2b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# need the page URL\n",
    "URL = \"\"\n",
    "\n",
    "# request to pull the page\n",
    "page = requests.get(URL)\n",
    "\n",
    "# pull the page through Beautiful Soup\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# variable to hold results from pulling the page through Beautiful soup\n",
    "results = soup.find(id=\"js-careers-root\")\n",
    "\n",
    "# The find_all() method scans the entire document looking for results\n",
    "#python_jobs = results.find_all(\n",
    "#    \"body\", string=lambda text: \"data\" in text.lower())\n",
    "\n",
    "\n",
    "# look at specific area of page\n",
    "python_jobs = results.find_all(\"body\", class_=\"div.jss-f8\", \n",
    "                            \n",
    "                            string=lambda text: \"data\" in text.lower()\n",
    ")\n",
    "\n",
    "#job_elements = results.find_all(\"div\", class_=\"div.jss-f8\")\n",
    "\n",
    "for job_element in python_jobs:\n",
    "    print(job_element, end=\"\\n\"*2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a674cf2-7ca3-470b-9e69-8eb342cd2fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON JOBS\n",
      "==============================\n",
      "\n",
      "Senior Python Developer\n",
      "Payne, Roberts and Davis\n",
      "Stewartbury, AA\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html\n",
      "\n",
      "\n",
      "Software Engineer (Python)\n",
      "Garcia PLC\n",
      "Ericberg, AE\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/software-engineer-python-10.html\n",
      "\n",
      "\n",
      "Python Programmer (Entry-Level)\n",
      "Moss, Duncan and Allen\n",
      "Port Sara, AE\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-20.html\n",
      "\n",
      "\n",
      "Python Programmer (Entry-Level)\n",
      "Cooper and Sons\n",
      "West Victor, AE\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-30.html\n",
      "\n",
      "\n",
      "Software Developer (Python)\n",
      "Adams-Brewer\n",
      "Brockburgh, AE\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/software-developer-python-40.html\n",
      "\n",
      "\n",
      "Python Developer\n",
      "Rivera and Sons\n",
      "East Michaelfort, AA\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/python-developer-50.html\n",
      "\n",
      "\n",
      "Back-End Web Developer (Python, Django)\n",
      "Stewart-Alexander\n",
      "South Kimberly, AA\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-60.html\n",
      "\n",
      "\n",
      "Back-End Web Developer (Python, Django)\n",
      "Jackson, Ali and Mckee\n",
      "New Elizabethside, AA\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-70.html\n",
      "\n",
      "\n",
      "Python Programmer (Entry-Level)\n",
      "Mathews Inc\n",
      "Robertborough, AP\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-80.html\n",
      "\n",
      "\n",
      "Software Developer (Python)\n",
      "Moreno-Rodriguez\n",
      "Martinezburgh, AE\n",
      "Apply here: https://realpython.github.io/fake-jobs/jobs/software-developer-python-90.html\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://realpython.github.io/fake-jobs/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"ResultsContainer\")\n",
    "\n",
    "# Look for Python jobs\n",
    "print(\"PYTHON JOBS\\n==============================\\n\")\n",
    "python_jobs = results.find_all(\n",
    "    \"h2\", string=lambda text: \"python\" in text.lower()\n",
    ")\n",
    "python_job_elements = [\n",
    "    h2_element.parent.parent.parent for h2_element in python_jobs\n",
    "]\n",
    "\n",
    "for job_element in python_job_elements:\n",
    "    title_element = job_element.find(\"h2\", class_=\"title\")\n",
    "    company_element = job_element.find(\"h3\", class_=\"company\")\n",
    "    location_element = job_element.find(\"p\", class_=\"location\")\n",
    "    print(title_element.text.strip())\n",
    "    print(company_element.text.strip())\n",
    "    print(location_element.text.strip())\n",
    "    link_url = job_element.find_all(\"a\")[1][\"href\"]\n",
    "    print(f\"Apply here: {link_url}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76258d-b4c7-4260-b221-4f7707283d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
